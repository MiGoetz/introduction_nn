{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaktive Beispiele von Neuronen und kleinen Neuronalen Netzen\n",
    "Die hier gezeigten, interaktiven Beispiele sollen helfen, die Funktionsweise von Neuronen und Neuronalen Netzen besser zu verstehen. \n",
    "\n",
    "Die Performance dieses Beispiels ist durch die Server von mybinder.org begrenzt. Deutlich performanter kann man dieses Jupyter Notebook lokal laufen lassen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "#%pylab inline\n",
    "\n",
    "from ipywidgets import interact, interactive, IntSlider, FloatSlider, Layout, HBox, VBox\n",
    "import operator\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = np.min(x), np.max(x)\n",
    "    y_min, y_max = np.min(y), np.max(y)\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    cmap = matplotlib.colors.ListedColormap([(249/255,106/255,27/255),(249/255,106/255,27/255),(57/255,180/255,225/255)])\n",
    "    #cmap = matplotlib.colors.LinearSegmentedColormap.from_list('Custom Two Color',[(249/255,106/255,27/255),(57/255,180/255,225/255)], N=512)\n",
    "    Z = clf(xx.ravel(),yy.ravel(),**params)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, cmap=cmap)\n",
    "    ax.set_xlim(left=-10.0,right=10.0)\n",
    "    ax.set_ylim(bottom=-10.0,top=10.0)\n",
    "    ax.set_ylabel('X_2')\n",
    "    ax.set_xlabel('X_1')\n",
    "    ax.set_xticks((-1,0,1))\n",
    "    ax.set_yticks((-1,0,1))\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    #plt.grid(True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def linear_decision_function(x,y,w,b=0, **params):\n",
    "    z=x*w[0] + y*w[1] + b\n",
    "    z[z>0]=1\n",
    "    z[z<=0]=0\n",
    "    return z\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def nonlinear_decision_function(x,y,w,b=0, **params):\n",
    "    z=sigmoid(x*w[0] + y*w[1] + b)\n",
    "    #z[z>0.5]=1\n",
    "    #z[z<=0.5]=0\n",
    "    return z\n",
    "\n",
    "def complex_network(x,y,w,b, **params):\n",
    "    z1=sigmoid(x*w[0] + y*w[1] + b[0])\n",
    "    z2=sigmoid(x*w[2] + y*w[3] + b[1])\n",
    "    z3=sigmoid(x*w[4] + y*w[5] + b[2])\n",
    "    y1=sigmoid(z1*w[6] + z2*w[7] + z3*w[8] + b[3])\n",
    "    y2=sigmoid(z1*w[9] + z2*w[10] + z3*w[11] + b[4])\n",
    "    y_hat=y1.copy()\n",
    "    y_hat[y1>y2]=1\n",
    "    y_hat[y1<=y2]=0\n",
    "    return y_hat\n",
    "\n",
    "#xx, yy = make_meshgrid([0,1],[0,1])\n",
    "#fig, ax = plt.subplots()\n",
    "#plot_contours(ax, linear_decision_function, xx,yy,w=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = make_meshgrid([-10,10],[-10,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaktives Beispiel eines einfaches, linearen Neuronalen Netzes\n",
    "Hier wird ein einfaches Neuron simuliert. Es besteht letztlich aus der gewichteten Summierung der Inputs. Das Beispiel korrespondiert mit dem Video auf Folie 6 der Vorlesung \"Einführung in Neuronale Netze\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb6c1b3018e41a699c69c8a4ae6104a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FloatSlider(value=0.4, description='\\\\(w_1\\\\)', max=1.0, min=-1.0), FloatSlider(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def func_decision_boarder_linear(w_1,w_2):\n",
    "    fig, ax= plt.subplots(figsize=(10, 8))\n",
    "    plot_contours(ax, linear_decision_function, xx,yy,w=[w_1,w_2])\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "pl=interactive(func_decision_boarder_linear,\n",
    "               w_1=FloatSlider(value=0.4, min=-1, max=1, step=0.1,description=r'\\(w_1\\)'), \n",
    "               w_2=FloatSlider(value=0.4, min=-1, max=1, step=0.1,description=r'\\(w_2\\)'))\n",
    "controls = VBox(pl.children[:-1])\n",
    "output = pl.children[-1]\n",
    "display(HBox([controls, output]))\n",
    "pl.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaktives Beispiel eines einfaches, linearen Neuronalen Netzes mit Offset\n",
    "Hier wird ein einfaches Neuron simuliert. Es besteht letztlich aus der gewichteten Summierung der Inputs plus einem frei wählbaren Offset. Das Beispiel korrespondiert mit dem Video auf Folie 8 der Vorlesung \"Einführung in Neuronale Netze\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9020f9cd7a9342f9a6b8d7df2ca9f6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FloatSlider(value=0.4, description='\\\\(w_1\\\\)', max=1.0, min=-1.0), FloatSlider(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def func_decision_boarder_linear_with_offest(w_1,w_2,b_1):\n",
    "    fig, ax= plt.subplots(figsize=(10, 8))\n",
    "    plot_contours(ax, linear_decision_function, xx,yy,w=[w_1,w_2],b=b_1*10)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "pl=interactive(func_decision_boarder_linear_with_offest,\n",
    "               w_1=FloatSlider(value=0.4, min=-1, max=1, step=0.1,description=r'\\(w_1\\)'), \n",
    "               w_2=FloatSlider(value=0.4, min=-1, max=1, step=0.1,description=r'\\(w_2\\)'),\n",
    "               b_1=FloatSlider(value=0.0, min=-1, max=1, step=0.1,description=r'\\(b_1\\)'))\n",
    "controls = VBox(pl.children[:-1])\n",
    "output = pl.children[-1]\n",
    "display(HBox([controls, output]))\n",
    "pl.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaktives Beispiel eines einfaches, nicht-linearen Neuronalen Netzes mit Offset\n",
    "Hier wird ein einfaches Neuron simuliert. Es besteht aus der gewichteten Summierung der Inputs plus einem frei wählbaren Offset und einer anschließenden Aktivierungsfunktion. Das Beispiel korrespondiert mit dem Neuron auf Folie 9 der Vorlesung \"Einführung in Neuronale Netze\"\n",
    "\n",
    "Als Aktivierungsfunktion wird die Sigmoid-Funktion genutzt. Die Farben codieren dabei die Bereiche größer bzw. kleiner 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7632dc54f7403099697cec80615377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FloatSlider(value=0.4, description='\\\\(w_1\\\\)', max=1.0, min=-1.0), FloatSlider(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def func_decision_boarder_nonlinear_with_offest(w_1,w_2,b_1):\n",
    "    fig, ax= plt.subplots(figsize=(10, 8))\n",
    "    plot_contours(ax, nonlinear_decision_function, xx,yy,w=[w_1,w_2],b=b_1*10)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "pl=interactive(func_decision_boarder_nonlinear_with_offest,\n",
    "               w_1=FloatSlider(value=0.4, min=-1, max=1, step=0.1,description=r'\\(w_1\\)'),\n",
    "               w_2=FloatSlider(value=0.4, min=-1, max=1, step=0.1,description=r'\\(w_2\\)'),\n",
    "               b_1=FloatSlider(value=0.4, min=-1, max=1, step=0.1,description=r'\\(b_1\\)'),\n",
    "              )\n",
    "controls = VBox(pl.children[:-1])\n",
    "output = pl.children[-1]\n",
    "display(HBox([controls, output]))\n",
    "pl.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaktives Beispiel eines einfaches, nicht-linearen Netzes\n",
    "Hier wird ein einfaches Netzwerk simuliert. Das Beispiel korrespondiert mit dem Neuron auf Folie 12 der Vorlesung \"Einführung in Neuronale Netze\"\n",
    "\n",
    "Als Aktivierungsfunktion wird die Sigmoid-Funktion genutzt. Die Farben codieren dabei welcher der Ausgabewerte größer ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d3c88710c34ce68cbf5700c1150b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FloatSlider(value=0.0, description='\\\\(w_1\\\\)', max=1.0, min=-1.0), FloatSlider(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def func_decision_boarder_complex_net(w_1,w_2,w_3,w_4,w_5,w_6,w_7,w_8,w_9,w_10,w_11,w_12,b_1,b_2,b_3,b_4,b_5):\n",
    "    fig, ax= plt.subplots(figsize=(10, 8))\n",
    "    plot_contours(ax, complex_network, xx,yy,w=[w_1,w_2,w_3,w_4,w_5,w_6,w_7,w_8,w_9,w_10,w_11,w_12],b=[b_1,b_2,b_3,b_4,b_5])\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "pl=interactive(func_decision_boarder_complex_net,\n",
    "               w_1=FloatSlider(value=0.0, min=-1, max=1, step=0.1,description=r'\\(w_1\\)'),\n",
    "               w_2=FloatSlider(value=0.1, min=-1, max=1, step=0.1,description=r'\\(w_2\\)'),\n",
    "               w_3=FloatSlider(value=-0.1, min=-1, max=1, step=0.1,description=r'\\(w_3\\)'),\n",
    "               w_4=FloatSlider(value=-0.1, min=-1, max=1, step=0.1,description=r'\\(w_4\\)'), \n",
    "               w_5=FloatSlider(value=-0.7, min=-1, max=1, step=0.1,description=r'\\(w_5\\)'),\n",
    "               w_6=FloatSlider(value=0.9, min=-1, max=1, step=0.1,description=r'\\(w_6\\)'),\n",
    "               w_7=FloatSlider(value=-0.1, min=-1, max=1, step=0.1,description=r'\\(w_7\\)'),\n",
    "               w_8=FloatSlider(value=0.3, min=-1, max=1, step=0.1,description=r'\\(w_8\\)'), \n",
    "               w_9=FloatSlider(value=0.6, min=-1, max=1, step=0.1,description=r'\\(w_9\\)'), \n",
    "               w_10=FloatSlider(value=0.5, min=-1, max=1, step=0.1,description=r'\\(w_{10}\\)'),\n",
    "               w_11=FloatSlider(value=0.0, min=-1, max=1, step=0.1,description=r'\\(w_{11}\\)'),\n",
    "               w_12=FloatSlider(value=0.3, min=-1, max=1, step=0.1,description=r'\\(w_{12}\\)'),\n",
    "               b_1=FloatSlider(value=0.3, min=-1, max=1, step=0.1,description=r'\\(b_1\\)'),\n",
    "               b_2=FloatSlider(value=0.8, min=-1, max=1, step=0.1,description=r'\\(b_2\\)'), \n",
    "               b_3=FloatSlider(value=-0.3, min=-1, max=1, step=0.1,description=r'\\(b_3\\)'),\n",
    "               b_4=FloatSlider(value=0.0, min=-1, max=1, step=0.1,description=r'\\(b_4\\)'), \n",
    "               b_5=FloatSlider(value=0.0, min=-1, max=1, step=0.1,description=r'\\(b_5\\)')\n",
    "              )\n",
    "controls = VBox(pl.children[:-1])\n",
    "output = pl.children[-1]\n",
    "display(HBox([controls, output]))\n",
    "pl.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaktives Beispiel einer Sigmoid-Aktivierungsfunktion\n",
    "Ein einfaches Beispiel eines einfaches Neurons mit einem Input, Offset und einer Sigmoid-Aktivierungsfunktion. Das Beispiel kann genutzt werden, um sich den Einfluss der verschiedenen Parameter auf den Ausgabewert zu verdeutlichen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interactive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0b3212f4d500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m pl=interactive(func_plot_sigmoid,\n\u001b[0m\u001b[1;32m     23\u001b[0m                \u001b[0mw_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFloatSlider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'\\(w_1\\)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                \u001b[0mb_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFloatSlider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'\\(b_1\\)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'interactive' is not defined"
     ]
    }
   ],
   "source": [
    "def func_plot_sigmoid(w_1,b_1):\n",
    "    fig, ax= plt.subplots(figsize=(10, 8))\n",
    "    cmap = matplotlib.colors.ListedColormap([(249/255,106/255,27/255),(249/255,106/255,27/255),(57/255,180/255,225/255)])\n",
    "    #cmap = matplotlib.colors.LinearSegmentedColormap.from_list('Custom Two Color',[(249/255,106/255,27/255),(57/255,180/255,225/255)], N=512)\n",
    "    \n",
    "    x=np.linspace(-10,10,1001)\n",
    "    Z = sigmoid(x*w_1 + b_1)\n",
    "    out = ax.plot(x, Z)\n",
    "    ax.set_xlim(left=-10.0,right=10.0)\n",
    "    ax.set_ylim(bottom=-.10,top=1.1)\n",
    "    ax.set_ylabel('X_2')\n",
    "    ax.set_xlabel(r'X_1')\n",
    "    ax.set_xticks((-9,-8,-7,-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9))\n",
    "    ax.set_yticks((0,0.5,1))\n",
    "    #ax.set_xticks(())\n",
    "    #ax.set_yticks(())\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "pl=interactive(func_plot_sigmoid,\n",
    "               w_1=FloatSlider(value=1.0, min=-10, max=10, step=0.1,description=r'\\(w_1\\)'),\n",
    "               b_1=FloatSlider(value=0.3, min=-10, max=10, step=0.1,description=r'\\(b_1\\)')\n",
    "              )\n",
    "controls = VBox(pl.children[:-1])\n",
    "output = pl.children[-1]\n",
    "display(HBox([controls, output]))\n",
    "pl.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
